{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mp\n",
    "import math\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from scipy.io import arff\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Data_Load(data_path):\n",
    "    data =  arff.loadarff('.//Data//' + data_path)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    data = np.array(df)\n",
    "    m,n=data.shape\n",
    "    return data,m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_N_Y_k(data):\n",
    "    list_NY = []\n",
    "    list_data = list(data[:,-1])\n",
    "    N = list_data.count(b'N')\n",
    "    Y = list_data.count(b'Y')\n",
    "    k = math.floor(N/Y)\n",
    "    return N,Y,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def compute_scale(data,m,N,Y):\n",
    "    data_scaled=preprocessing.scale(data[:,:-1], axis=0, with_mean=True,with_std=True,copy=True) \n",
    "    data_scaled_NY = np.concatenate((data_scaled,data[:,-1].reshape(m,1)),axis=1)\n",
    "    index = np.arange(m)\n",
    "    data_scaled = np.concatenate((index.reshape(m,1),data_scaled_NY),axis=1)\n",
    "    data_scaled_N_index  = np.argwhere(data_scaled_NY[:,-1]==b'N')\n",
    "    data_scaled_Y_index  = np.argwhere(data_scaled_NY[:,-1]==b'Y')\n",
    "    data_scaled_N = data_scaled[data_scaled_N_index].reshape(N,n+1)\n",
    "    data_scaled_Y = data_scaled[data_scaled_Y_index].reshape(Y,n+1)\n",
    "    \n",
    "    return data_scaled_N,data_scaled_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Cal_Distance(data_scaled_N,data_scaled_Y,N,Y,k):\n",
    "    NY_distance_samples_neighbor = np.empty([0,3],float)\n",
    "    flag = 0\n",
    "    i=0\n",
    "    for s_Y in data_scaled_Y:\n",
    "        temp_arr = np.array([])\n",
    "        for s_N in data_scaled_N:\n",
    "            temp = np.linalg.norm(s_N[1:n]-s_Y[1:n])\n",
    "            temp_arr = np.append(temp_arr,temp)\n",
    "\n",
    "        temp_arr = temp_arr.reshape((N,1))\n",
    "        NY_distance = np.concatenate((data_scaled_Y[[i],[0]].repeat(N).reshape(N,1),data_scaled_N[:,[0]],temp_arr),axis=1)\n",
    "        NY_distance_sample_neighbor = NY_distance[NY_distance[:,2].argsort()].reshape(N,3)[0:k,:]\n",
    "        NY_distance_samples_neighbor = np.append(NY_distance_samples_neighbor,NY_distance_sample_neighbor,axis=0)\n",
    "        i = i+1\n",
    "    return NY_distance_samples_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Cal_Feature_Differential(data,NY_distance_samples_neighbor,m,n):\n",
    "    w_matrix = np.zeros(n-1).reshape(1,n-1)\n",
    "    NY_M,NY_N = NY_distance_samples_neighbor.shape\n",
    "    index_ny = NY_distance_samples_neighbor[0:NY_M,0:NY_N-1]\n",
    "\n",
    "    index_y = index_ny[0:NY_M,0].reshape(NY_M).astype(int)\n",
    "    index_n = index_ny[0:NY_M,1].reshape(NY_M).astype(int)\n",
    "\n",
    "    index_last = np.arange(m)\n",
    "    data_filter = np.concatenate((index_last.reshape(m,1),data.copy()),axis=1)\n",
    "\n",
    "    samples_feature_differential = np.abs(data_filter[list(index_y),1:n]-data_filter[list(index_n),1:n])\n",
    "\n",
    "    feature_index = np.arange(n-1).reshape(1,n-1)\n",
    "    \n",
    "    for feature_differential in samples_feature_differential:\n",
    "        temp_feature = np.concatenate((feature_index,feature_differential.reshape(1,n-1)),axis=0)\n",
    "        temp_sorted_feature = temp_feature[:,temp_feature[1].argsort()]\n",
    "        feature = temp_sorted_feature[1,:].copy()\n",
    "        j = 1 \n",
    "        temp_w = np.empty(n-1)\n",
    "        temp_w[0] = j\n",
    "        for i in range(n-1):\n",
    "            if i!=0 :\n",
    "                if  feature[i-1]==feature[i]:\n",
    "                    temp_w[i] = j\n",
    "                else:\n",
    "                    j = j+1\n",
    "                    temp_w[i] = j\n",
    "        temp_sorted_feature[1,:]=temp_w\n",
    "        temp_last_feature  = temp_sorted_feature[:,temp_sorted_feature[0].argsort()]\n",
    "        w_matrix = np.add(temp_last_feature[1,:],w_matrix)\n",
    "        \n",
    "    index = np.arange(n-1).reshape(1,n-1)\n",
    "    last = np.concatenate((index,w_matrix),axis=0)\n",
    "    last = last[:,last[1].argsort()][::,::-1]\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "def Train_Measure(X,y,clf):\n",
    "#     print(\"x:  \")\n",
    "#     print(X)\n",
    "#     print(\"y:  \")\n",
    "#     print(y)\n",
    "    auc1 = np.empty(100)\n",
    "    count = 0\n",
    "    rkf = RepeatedKFold(n_splits=10,n_repeats=10)\n",
    "    for train_index,test_index in rkf.split(X):\n",
    "        x_train,x_test = X[train_index],X[test_index]\n",
    "        y_train,y_test = y[train_index],y[test_index]\n",
    "        clf.fit(x_train,y_train)\n",
    "        pre_y = clf.predict_proba(x_test)[:,1]\n",
    "        fpr,tpr,thresholds = roc_curve(y_test,pre_y)\n",
    "        auc1[count] = auc(fpr,tpr)\n",
    "        count += 1\n",
    "    auc1 = np.nanmean(auc1)\n",
    "    return auc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def Model_Initialize():\n",
    "    clf_svm = svm.SVC(gamma='auto',probability=True)\n",
    "    clf_bayes = naive_bayes.GaussianNB()\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    return clf_svm,clf_bayes,clf_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM1.arff\n",
      "d: 5\n",
      "JM1.arff\n",
      "d: 4\n",
      "KC1.arff\n",
      "d: 4\n",
      "KC3.arff\n",
      "d: 5\n",
      "MC1.arff\n",
      "d: 5\n",
      "MC2.arff\n",
      "d: 5\n",
      "MW1.arff\n",
      "d: 5\n",
      "PC1.arff\n",
      "d: 5\n",
      "PC2.arff\n",
      "d: 5\n",
      "PC3.arff\n",
      "d: 5\n",
      "PC4.arff\n",
      "d: 5\n",
      "PC5.arff\n",
      "d: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "if __name__ == '__main__':\n",
    "    files = os.listdir('.//Data')\n",
    "    for file in files:\n",
    "        \n",
    "        # Original_Data,m,n = Data_Load(file)\n",
    "        # N,Y,k = compute_N_Y_k(Original_Data)\n",
    "        # data_scaled_N,data_scaled_Y = compute_scale(Original_Data,m,N,Y)\n",
    "        # NY_distance_samples_neighbor = Cal_Distance(data_scaled_N,data_scaled_Y,N,Y,k)\n",
    "        # Feature_Sequence = Cal_Feature_Differential(Original_Data,NY_distance_samples_neighbor,m,n).astype(np.int32)\n",
    "        # data_scaled_N_Y = np.concatenate((data_scaled_N,data_scaled_Y),axis=0)\n",
    "        # data_scaled_N_Y = data_scaled_N_Y[data_scaled_N_Y[:,0].argsort()]\n",
    "        # data = data_scaled_N_Y[:,Feature_Sequence[0,:]+1]\n",
    "        # #将N,Y变换为0，1\n",
    "        # lookupTable,label = np.unique(data_scaled_N_Y[:,n], return_inverse=True)\n",
    "        # data = np.concatenate((data,label.reshape(-1,1)),axis=1)\n",
    "        # if os.path.exists(file+'.txt'):\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     np.savetxt(file+'.txt',data)\n",
    "\n",
    "#         if os.path.exists(file+'.csv'):\n",
    "#             continue\n",
    "        data = np.loadtxt('.\\\\txtdata\\\\'+str(file)+'.txt')\n",
    "        m,n = data.shape\n",
    "        print(file)\n",
    "        d = int(math.log(n-1,2))\n",
    "        print(\"d: \"+ str(d))\n",
    "\n",
    "#         clfs = Model_Initialize()\n",
    "#         Feature_index = list(range(1,n+1))\n",
    "#         roc_f1_columns = ['roc_auc_svm','roc_auc_byes','roc_auc_tree'] \n",
    "#         auc_Array = np.array([])\n",
    "#         for i in range(n):\n",
    "#             print(\"Feature 1 To \"+str(i+1))\n",
    "#             for clf in clfs:    \n",
    "#                 mean_auc = Train_Measure(data[:,0:i+1],data[:,-1],clf)\n",
    "#                 auc_Array= np.append(auc_Array,mean_auc)\n",
    "#             auc_Array = auc_Array.reshape(-1,3)\n",
    "#         df = pd.DataFrame(auc_Array,index=Feature_index,columns=roc_f1_columns)\n",
    "#         print(file+'   '+'_roc_auc:  ')\n",
    "#         print(df)\n",
    "#         df.to_csv(file+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
